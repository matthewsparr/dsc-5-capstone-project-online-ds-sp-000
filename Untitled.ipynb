{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\sparr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\sparr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from subprocess import Popen, PIPE, STDOUT\n",
    "from queue import Queue, Empty\n",
    "from threading  import Thread\n",
    "from time import sleep\n",
    "import os\n",
    "import urllib\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import ast\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "import string\n",
    "import pickle\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.attrs import POS\n",
    "import spacy\n",
    "import requests\n",
    "import pandas as pd\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enqueue_output(out, queue):\n",
    "    for line in iter(out.readline, b''):\n",
    "        queue.put(line)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(link):\n",
    "\n",
    "    return_links = []\n",
    "\n",
    "    r = requests.get(link)\n",
    "\n",
    "    soup = BeautifulSoup(r.content, \"lxml\")\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        print(\"Error. Something is wrong here\")\n",
    "    else:\n",
    "        for link in soup.findAll('a', attrs={'href': re.compile(\"^\")}):\n",
    "            address = link.get('href')\n",
    "            if ('.z5' in address or '.z3' in address or '.z8' in address):\n",
    "                return_links.append('https://ifarchive.org/'+address[2:])\n",
    "    return return_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = get_links('https://ifarchive.org/indexes/if-archiveXgamesXzcode.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://ifarchive.org//if-archive/games/zcode/7doctors.z5'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_games_and_grammar(links):\n",
    "    for url in links:\n",
    "        file_name = url.split('/')[-1]\n",
    "        r = requests.get(url, allow_redirects=True, stream=True)\n",
    "        f = open(file_name, 'wb')\n",
    "        f.write(r.content)\n",
    "        f.close()\n",
    "        \n",
    "        p = Popen(['infodump.exe', '-g', file_name], stdin=PIPE, stdout=PIPE, stderr=PIPE, shell=True)\n",
    "        text = p.communicate()[0].decode('utf-8', errors='ignore').strip()\n",
    "        f = open('grammar/' + file_name[:-3] + '.txt', 'w')\n",
    "        f.write(text)\n",
    "        f.close()\n",
    "        p.terminate()\n",
    "        p.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_games_and_grammar(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add('Action-Determiner-Object', None, [{POS: 'VERB'}, {POS: 'DET', 'OP':'*'}, {POS: 'ADJ', 'OP':'*'}, {POS: 'NOUN'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher2 = Matcher(nlp.vocab)\n",
    "matcher2.add('Action-Determiner-Object', None, [{POS: 'VERB'}, {POS: 'DET', 'OP':'*'}, {POS: 'ADJ', 'OP':'*'}, {POS: 'NOUN'},\n",
    "                                               {POS: 'ADP'}, {POS: 'DET', 'OP':'*'}, {POS: 'ADJ', 'OP':'*'}, {POS: 'NOUN'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher3 = Matcher(nlp.vocab)\n",
    "matcher3.add('Action-Determiner-Object', None, [{POS: 'VERB'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "throw the rock at house "
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'throw the rock at house '\n",
    "doc = nlp(string)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12505529351931920348, 0, 3)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = matcher(doc)\n",
    "matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10% |#######                                                                 |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21% |###############                                                         |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72% |####################################################                    |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90% |################################################################        |\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    }
   ],
   "source": [
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "commands = []\n",
    "commands2 = []\n",
    "directory = os.fsencode(os.getcwd()+'\\\\grammar')\n",
    "for link in pbar(links):\n",
    "    file_name = link.split('/')[-1]\n",
    "    text_file = file_name[:-3] + '.txt'\n",
    "    f = open('grammar/' + text_file, 'r')\n",
    "    text = f.read().strip()\n",
    "    text = re.sub(r'([^\\s\\w]|_)+', '', text)\n",
    "    if (len(text) > 100000):\n",
    "        print('large file')\n",
    "        text = text[0:100000]\n",
    "    doc = nlp(text)\n",
    "    matches = matcher(doc)\n",
    "    matches2 = matcher2(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        span = doc[start:end]\n",
    "        #verb = WordNetLemmatizer().lemmatize(str(nlp(span.text)[0]),'v')\n",
    "        #text = verb + \" \" + str(nlp(span.text)[1:])\n",
    "        commands.append(span)\n",
    "    for match_id, start, end in matches2:\n",
    "        span = doc[start:end]\n",
    "        #verb = WordNetLemmatizer().lemmatize(str(nlp(span.text)[0]),'v')\n",
    "        #text = verb + \" \" + str(nlp(span.text)[1:])\n",
    "        commands2.append(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "no default __reduce__ due to non-trivial __cinit__",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-75500faa1432>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'commands_games.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommands\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\spacy\\tokens\\span.cp35-win_amd64.pyd\u001b[0m in \u001b[0;36mspacy.tokens.span.Span.__reduce_cython__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: no default __reduce__ due to non-trivial __cinit__"
     ]
    }
   ],
   "source": [
    "with open('commands_games.txt', 'wb') as cmd:\n",
    "    pickle.dump(commands, cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "game_commands = pd.DataFrame(commands)\n",
    "game_commands2 = pd.DataFrame(commands2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_commands.to_csv('game_commands.csv')\n",
    "game_commands2.to_csv('game_commands2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>noscript</td>\n",
       "      <td>synonyms</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>carry</td>\n",
       "      <td>inventory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>carry</td>\n",
       "      <td>noun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>carry</td>\n",
       "      <td>noun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>using</td>\n",
       "      <td>noun</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         0          1    2    3    4\n",
       "0           0  noscript   synonyms  NaN  NaN  NaN\n",
       "1           1     carry  inventory  NaN  NaN  NaN\n",
       "2           2     carry       noun  NaN  NaN  NaN\n",
       "3           3     carry       noun  NaN  NaN  NaN\n",
       "4           4     using       noun  NaN  NaN  NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc = pd.read_csv('game_commands.csv')\n",
    "gc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>carry</td>\n",
       "      <td>noun</td>\n",
       "      <td>with</td>\n",
       "      <td>noun</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>remove</td>\n",
       "      <td>noun</td>\n",
       "      <td>with</td>\n",
       "      <td>noun</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>consult</td>\n",
       "      <td>noun</td>\n",
       "      <td>on</td>\n",
       "      <td>topic</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>read</td>\n",
       "      <td>topic</td>\n",
       "      <td>in</td>\n",
       "      <td>noun</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>drag</td>\n",
       "      <td>noun</td>\n",
       "      <td>under</td>\n",
       "      <td>noun</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        0      1      2      3    4\n",
       "0           0    carry   noun   with   noun  NaN\n",
       "1           1   remove   noun   with   noun  NaN\n",
       "2           2  consult   noun     on  topic  NaN\n",
       "3           3     read  topic     in   noun  NaN\n",
       "4           4     drag   noun  under   noun  NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc2 = pd.read_csv('game_commands2.csv')\n",
    "gc2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "put        1883\n",
       "rotate     1729\n",
       "ask        1633\n",
       "carry      1221\n",
       "burn       1169\n",
       "discard    1018\n",
       "read        933\n",
       "tell        928\n",
       "adjust      926\n",
       "hear        790\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc['0'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "noun           9094\n",
       "creature       2326\n",
       "multiexcept    2319\n",
       "synonyms       2099\n",
       "topic          1077\n",
       "multiheld       744\n",
       "inventory       735\n",
       "multi           504\n",
       "parse           454\n",
       "CREATURE        354\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc['1'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ask        1390\n",
       "tell        711\n",
       "consult     593\n",
       "read        375\n",
       "attach      134\n",
       "adjust      125\n",
       "pour         60\n",
       "put          53\n",
       "rotate       53\n",
       "carry        27\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc2['0'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "creature       1863\n",
       "noun           1265\n",
       "topic           388\n",
       "CREATURE        227\n",
       "multiheld        17\n",
       "sex              13\n",
       "multiexcept      12\n",
       "hands            12\n",
       "ATTRIBUTE0       11\n",
       "click            10\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc2['1'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "about    1604\n",
       "for       617\n",
       "on        531\n",
       "in        439\n",
       "to        364\n",
       "with      165\n",
       "from       55\n",
       "at         46\n",
       "of         41\n",
       "into       30\n",
       "Name: 2, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc2['2'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic         1829\n",
       "noun          1507\n",
       "TEXT           215\n",
       "scope          152\n",
       "number          45\n",
       "parse           36\n",
       "creature        19\n",
       "fire            16\n",
       "ATTRIBUTE0      10\n",
       "SCOPE            9\n",
       "Name: 3, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc2['3'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getZorkGrammar():\n",
    "    file_name = 'zork1.z5'\n",
    "    p = Popen(['infodump.exe', '-g', file_name], stdin=PIPE, stdout=PIPE, stderr=PIPE, shell=True)\n",
    "    text = p.communicate()[0].decode('utf-8', errors='ignore').strip()\n",
    "    f = open(file_name[:-3] + '.txt', 'w')\n",
    "    f.write(text)\n",
    "    f.close()\n",
    "    p.terminate()\n",
    "    p.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "getZorkGrammar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('zork1.txt', 'r')\n",
    "zorkGrammar = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "zorkGrammar = re.sub(r'([^\\s\\w]|_)+', '', zorkGrammar.strip()).replace('OBJ', 'object').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "zorkCommands = []\n",
    "zorkCommands2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(zorkGrammar)\n",
    "matches = matcher(doc)\n",
    "matches2 = matcher2(doc)\n",
    "matches3 = matcher3(doc)\n",
    "for match_id, start, end in matches3:\n",
    "    span = doc[start:end].text\n",
    "    zorkCommands.append(span)\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end].text\n",
    "    zorkCommands.append(span)\n",
    "for match_id, start, end in matches2:\n",
    "    span = doc[start:end].text\n",
    "    zorkCommands.append(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = sorted(list(set(zorkCommands)), key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.remove('f5')\n",
    "z.remove('synonyms')\n",
    "z.remove('prepositions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [p.replace('synonyms', 'object') for p in z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d',\n",
       " 's',\n",
       " 'is',\n",
       " 'go',\n",
       " 'ca',\n",
       " 've',\n",
       " 'hit',\n",
       " 'win',\n",
       " 'cut',\n",
       " 'put',\n",
       " 'sit',\n",
       " 'see',\n",
       " 'dig',\n",
       " 'set',\n",
       " 'eat',\n",
       " 'get',\n",
       " 'fix',\n",
       " 'say',\n",
       " 'ask',\n",
       " 'dive',\n",
       " 'move',\n",
       " 'skim',\n",
       " 'slay',\n",
       " 'make',\n",
       " 'kick',\n",
       " 'blow',\n",
       " 'save',\n",
       " 'give',\n",
       " 'pour',\n",
       " 'take',\n",
       " 'find',\n",
       " 'lose',\n",
       " 'lift',\n",
       " 'open',\n",
       " 'toss',\n",
       " 'come',\n",
       " 'pump',\n",
       " 'wait',\n",
       " 'play',\n",
       " 'swim',\n",
       " 'pick',\n",
       " 'flip',\n",
       " 'read',\n",
       " 'wear',\n",
       " 'kill',\n",
       " 'hide',\n",
       " 'echo',\n",
       " 'send',\n",
       " 'melt',\n",
       " 'wake',\n",
       " 'tell',\n",
       " 'stay',\n",
       " 'roll',\n",
       " 'pull',\n",
       " 'burn',\n",
       " 'quit',\n",
       " 'pray',\n",
       " 'lean',\n",
       " 'wade',\n",
       " 'feel',\n",
       " 'zork',\n",
       " 'wish',\n",
       " 'fill',\n",
       " 'climb',\n",
       " 'bathe',\n",
       " 'swing',\n",
       " 'shout',\n",
       " 'curse',\n",
       " 'enter',\n",
       " 'break',\n",
       " 'leave',\n",
       " 'block',\n",
       " 'raise',\n",
       " 'knock',\n",
       " 'stand',\n",
       " 'using',\n",
       " 'shake',\n",
       " 'carry',\n",
       " 'spray',\n",
       " 'apply',\n",
       " 'treasu',\n",
       " 'exting',\n",
       " 'banish',\n",
       " 'froboz',\n",
       " 'unlock',\n",
       " 'diagno',\n",
       " 'brandi',\n",
       " 'donate',\n",
       " 'remove',\n",
       " 'scream',\n",
       " 'thrust',\n",
       " 'ulysse',\n",
       " 'inflat',\n",
       " 'listen',\n",
       " 'versio',\n",
       " 'squeez',\n",
       " 'enchan',\n",
       " 'object',\n",
       " 'repent',\n",
       " 'attach',\n",
       " 'get grab',\n",
       " 'see seek',\n",
       " 'set shut',\n",
       " 'hit hurt',\n",
       " 'go object',\n",
       " 'eat taste',\n",
       " 'put stuff',\n",
       " 'is zork1z5',\n",
       " 'cut object',\n",
       " 'dig object',\n",
       " 'shout yell',\n",
       " 'ask object',\n",
       " 'fix object',\n",
       " 'give offer',\n",
       " 'make object',\n",
       " 'wear object',\n",
       " 'move object',\n",
       " 'kick object',\n",
       " 'kill murder',\n",
       " 'find object',\n",
       " 'play object',\n",
       " 'feel object',\n",
       " 'hide object',\n",
       " 'read object',\n",
       " 'come follow',\n",
       " 'fill object',\n",
       " 'go object',\n",
       " 'flip object',\n",
       " 'burn object',\n",
       " 'pick object',\n",
       " 'pour object',\n",
       " 'pull object',\n",
       " 'apply object',\n",
       " 'leave object',\n",
       " 'ask object',\n",
       " 'break damage',\n",
       " 'enter object',\n",
       " 'curse object',\n",
       " 'shake object',\n",
       " 'carry object',\n",
       " 'spray object',\n",
       " 'burn object',\n",
       " 'inflat object',\n",
       " 'brandi object',\n",
       " 'donate object',\n",
       " 'squeez object',\n",
       " 'attach object',\n",
       " 'find object',\n",
       " 'unlock object',\n",
       " 'banish object',\n",
       " 'read object',\n",
       " 'wait object',\n",
       " 'enchan object',\n",
       " 'feel object',\n",
       " 'pour object',\n",
       " 'pour object on object',\n",
       " 'hide object in object',\n",
       " 'pour object in object',\n",
       " 'move object in object',\n",
       " 'hide object on object',\n",
       " 'flip object for object',\n",
       " 'fix object with object',\n",
       " 'spray object on object',\n",
       " 'dig object with object',\n",
       " 'cut object with object',\n",
       " 'pick object with object',\n",
       " 'squeez object on object',\n",
       " 'pour object from object',\n",
       " 'fill object with object',\n",
       " 'brandi object at object',\n",
       " 'burn object with object',\n",
       " 'flip object with object',\n",
       " 'read object with object',\n",
       " 'hide object under object',\n",
       " 'carry object from object',\n",
       " 'inflat object with object']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
