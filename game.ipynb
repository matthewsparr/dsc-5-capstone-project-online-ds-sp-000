{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\sparr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\sparr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "class text_game:\n",
    "    from subprocess import Popen, PIPE, STDOUT\n",
    "    from random import randint\n",
    "    import binascii\n",
    "    import os\n",
    "    from queue import Queue, Empty\n",
    "    from threading  import Thread\n",
    "    from time import sleep\n",
    "    import random\n",
    "    import nltk\n",
    "    nltk.download('averaged_perceptron_tagger')\n",
    "    from itertools import permutations, combinations\n",
    "    import spacy\n",
    "    from spacy.matcher import Matcher\n",
    "    from spacy.attrs import POS\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    import pandas as pd\n",
    "    nltk.download('punkt')\n",
    "    import numpy as np\n",
    "    import gensim\n",
    "    from gensim.models import KeyedVectors\n",
    "    from gensim.models import Word2Vec\n",
    "    from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "    import timeit\n",
    "    from keras.models import Model\n",
    "    from keras.preprocessing.text import one_hot, Tokenizer\n",
    "    from keras.preprocessing.sequence import pad_sequences\n",
    "    import re\n",
    "    from agent import DQNAgent as DQNAgent\n",
    "    import importlib\n",
    "    from collections import deque\n",
    "    from numpy.random import choice\n",
    "    import math\n",
    "    import pickle\n",
    "    from progressbar import ProgressBar\n",
    "    from agent import DQNAgent\n",
    "    from game_commands import commands\n",
    " \n",
    "    def __init__(self):\n",
    "        \n",
    "        import agent\n",
    "        from agent import DQNAgent\n",
    "        self.emulator_file = 'dfrotz.exe'\n",
    "        \n",
    "        self.agent = DQNAgent()\n",
    "        \n",
    "        self.p = None\n",
    "        self.q = None\n",
    "        self.t = None\n",
    "        \n",
    "        self.word_2_vec = None\n",
    "        self.tutorials_text = 'tutorials_2.txt'\n",
    "        \n",
    "        self.tokenizer = None\n",
    "        self.vocab_size = 800\n",
    "        \n",
    "        self.sleep_time = 0.1\n",
    "        self.random_action_weight = 4\n",
    "        self.random_action_basic_prob = 0.5\n",
    "        self.random_action_low_prob = 0.2\n",
    "        self.game_score_weight = 5\n",
    "        self.negative_per_turn_reward = 1\n",
    "        self.inventory_reward_value = 20\n",
    "        self.new_area_reward_value = 10\n",
    "        \n",
    "        import game_commands\n",
    "        from game_commands import commands\n",
    "        \n",
    "        cmds = commands()\n",
    "        self.basic_actions = cmds.basic_actions\n",
    "        self.directions = cmds.directions\n",
    "        self.command1_actions = cmds.command1_actions\n",
    "        self.command2_actions = cmds.command2_actions\n",
    "        self.action_space = cmds.action_space\n",
    "        self.filtered_tokens = cmds.filtered_tokens\n",
    "        self.invalid_nouns = [] \n",
    "        \n",
    "        self.story = pd.DataFrame(columns=['Surroundings', 'Inventory', 'Action', 'Response', 'Score', 'Moves'])\n",
    "        \n",
    "    def __create_agent(self):\n",
    "        dqna = DQNAgent()\n",
    "        return dqna\n",
    "    \n",
    "    def enqueue_output(self, out, queue):\n",
    "        for line in iter(out.readline, b''):\n",
    "            queue.put(line)\n",
    "        out.close()\n",
    "\n",
    "    def start_game(self, game_file):\n",
    "        load_invalid_nouns()\n",
    "        init_word2vec()\n",
    "        init_tokenizer()\n",
    "        \n",
    "        score = 0\n",
    "        moves = 0\n",
    "        p = Popen([emulator_file,game_file], stdin=PIPE, stdout=PIPE, stderr=PIPE, shell=True)\n",
    "        q = Queue()\n",
    "        t = Thread(target=enqueue_output, args=(p.stdout, q))\n",
    "        t.daemon = True # thread dies with the program\n",
    "        t.start()\n",
    "        sleep(sleep_time)\n",
    "        return(p, q, t, score, moves)\n",
    "    \n",
    "    def end_game(self):\n",
    "        save_invalid_nouns()\n",
    "        kill_game()\n",
    "        \n",
    "    def kill_game(self, p):\n",
    "        p.terminate()\n",
    "        p.kill()\n",
    "\n",
    "    # read line without blocking\n",
    "    def readLine(self, q):\n",
    "        cont = True\n",
    "        narrative = \"\"\n",
    "        while cont:\n",
    "            try:  line = q.get_nowait() # or q.get(timeout=.1)\n",
    "            except Empty:\n",
    "                cont = False\n",
    "            else: \n",
    "                narrative = narrative + line.decode(\"utf-8\").replace('\\n', \" \").replace('\\r', \" \")\n",
    "        if ('840726' in narrative): ## Opening narrative\n",
    "            narrative = narrative[narrative.index('840726') + len('840726'):]\n",
    "        try:\n",
    "            score, moves = grab_score_moves(narrative)\n",
    "            narrative = narrative[narrative.index('Moves: ')+len('Moves:')+5:-1].strip()\n",
    "        except:  ## not valid move\n",
    "            pass\n",
    "        sleep(sleep_time)\n",
    "        return(narrative, score, moves)\n",
    "\n",
    "    def grab_score_moves(self, narrative):\n",
    "        try:\n",
    "            score = int(narrative[narrative.index('Score: ') + len('Score: '):][0:3].strip())\n",
    "            moves = int(narrative[narrative.index('Moves: ') + len('Moves: '):][0:3].strip())\n",
    "        except:  ## not valid move\n",
    "            score = 0\n",
    "            moves = 0\n",
    "        return(score, moves)\n",
    "\n",
    "    def look_surroundings(self, p):\n",
    "        perform_action('look', p)\n",
    "\n",
    "    def check_inventory(self, p):\n",
    "        perform_action('inventory', p)\n",
    "\n",
    "    def get_nouns(self, narrative):\n",
    "        matcher = Matcher(nlp.vocab)\n",
    "        matcher.add('Noun phrase', None, [{POS: 'NOUN'}])\n",
    "        doc = nlp(narrative)\n",
    "        matches = matcher(doc)\n",
    "        noun_list = [doc[start:end].text for id, start, end in matches]\n",
    "        for direction in directions:\n",
    "            if direction in noun_list:\n",
    "                noun_list.remove(direction)\n",
    "        for invalid in invalid_nouns:\n",
    "            if invalid in noun_list:\n",
    "                noun_list.remove(invalid)\n",
    "        return(noun_list)\n",
    "    \n",
    "    def generate_action_tuples(self, nouns):\n",
    "        possible_actions = []\n",
    "        similarities = []\n",
    "        for i in basic_actions:\n",
    "            possible_actions.append(i)\n",
    "            similarities.append(random_action_basic_prob)\n",
    "        for i in nouns:\n",
    "            for action1 in command1_actions:   ## first loop replaces 'x' in each action in command1_actions\n",
    "                action_to_add = action1.replace('OBJ', i)\n",
    "                possible_actions.append(action_to_add)\n",
    "                try:\n",
    "                    similarities.append(model.similarity(word_tokenize(action_to_add)[0], i))\n",
    "                except:\n",
    "                    similarities.append(random_action_low_prob)\n",
    "            noun_permutations = list(permutations(nouns, 2))    ## second loop replaces 'x' and 'y' in each action in command2_actions\n",
    "            for action2 in command2_actions:\n",
    "                for perm in noun_permutations:\n",
    "                    if (perm[0] == perm[1]):  ## ignore same noun acting on itself\n",
    "                        pass\n",
    "                    else:\n",
    "                        action_to_add = action2.replace('OBJ', perm[0])\n",
    "                        action_to_add = action_to_add.replace('DCT', perm[1])\n",
    "                        possible_actions.append(action_to_add)\n",
    "                        try:\n",
    "                            similarities.append(model.similarity(word_tokenize(action_to_add)[0], i))\n",
    "                        except:\n",
    "                            similarities.append(random_action_low_prob)\n",
    "\n",
    "        return possible_actions\n",
    "    \n",
    "    def selectOne(self, action_space, similarities):\n",
    "        return action_space[choice(len(action_space), p=similarities)]\n",
    "    \n",
    "    def add_to_action_space(self, action_space, actions):\n",
    "        ## \n",
    "        \n",
    "        similarities = []\n",
    "\n",
    "        for action in actions:\n",
    "            action_space.add(action)\n",
    "        for action in action_space:\n",
    "            words = word_tokenize(action)\n",
    "            verb = words[0]\n",
    "            if verb in basic_actions:    ## basic commands i.e. go north, go south\n",
    "                similarities.append(random_action_basic_prob)\n",
    "            elif len(words)<3:           ## commands with one noun i.e. open mailbox, read letter\n",
    "                noun = word_tokenize(action)[1]\n",
    "                try:\n",
    "                    sim_score = model.similarity(verb, noun)**random_action_weight\n",
    "                    if sim_score < 0:\n",
    "                        sim_score = random_action_basic_prob**random_action_weight\n",
    "                    similarities.append(sim_score)\n",
    "                except:\n",
    "                    similarities.append(random_action_low_prob**random_action_weight)\n",
    "\n",
    "            else:                       ## commands with two nouns i.e. unlock chest with key\n",
    "                try:\n",
    "                    noun1 = word_tokenize(action)[1]\n",
    "                    prep = word_tokenize(action)[2]\n",
    "                    noun2 = word_tokenize(action)[3]\n",
    "                    sim_score1 = model.similarity(verb, noun1)\n",
    "                    sim_score2 = model.similarity(prep, noun2)\n",
    "                    sim_score = ((sim_score1 + sim_score2)/2)**random_action_weight\n",
    "                    if sim_score < 0:\n",
    "                        sim_score = 0.05\n",
    "                    similarities.append(sim_score**random_action_weight)\n",
    "                except:\n",
    "                    similarities.append(random_action_low_prob**random_action_weight)\n",
    "\n",
    "\n",
    "        return action_space, similarities\n",
    "        \n",
    "    def perform_action(self, command, p):\n",
    "        p.stdin.write(bytes(command+ \"\\n\", 'ascii'))\n",
    "        p.stdin.flush()\n",
    "        sleep(sleep_time)## wait for action to register\n",
    "        \n",
    "    def preprocess(self, text):\n",
    "        # fix bad newlines (replace with spaces), unify quotes\n",
    "        text = text.strip()\n",
    "        text = text.replace('\\\\n', ' ').replace('‘', '\\'').replace('’', '\\'').replace('”', '\"').replace('“', '\"')\n",
    "        # convert to lowercase\n",
    "        text = text.lower()\n",
    "        # remove all characters except alphanum, spaces and - ' \"\n",
    "        text = re.sub('[^ \\-\\sA-Za-z0-9\"\\']+', ' ', text)\n",
    "        # split numbers into digits to avoid infinite vocabulary size if random numbers are present:\n",
    "        text = re.sub('[0-9]', ' \\g<0> ', text)\n",
    "        # expand unambiguous 'm, 't, 're, ... expressions\n",
    "        text = text. \\\n",
    "                replace('\\'m ', ' am '). \\\n",
    "                replace('\\'re ', ' are '). \\\n",
    "                replace('won\\'t', 'will not'). \\\n",
    "                replace('n\\'t', ' not'). \\\n",
    "                replace('\\'ll ', ' will '). \\\n",
    "                replace('\\'ve ', ' have '). \\\n",
    "                replace('\\'s', ' \\'s')\n",
    "        return text\n",
    "    \n",
    "    def vectorize_text(text, tokenizer):\n",
    "        text = preprocess(text)\n",
    "        words = word_tokenize(text)\n",
    "        tokenizer.fit_on_texts(words)\n",
    "        seq = tokenizer.texts_to_sequences(words)\n",
    "        sent = []\n",
    "        for i in seq:\n",
    "            sent.append(i[0])\n",
    "        padded = pad_sequences([sent], maxlen=50, padding='post')\n",
    "        return (padded)\n",
    "    \n",
    "    def calculate_reward(self, story, moves_count, new_narrative):\n",
    "        reward = 0\n",
    "\n",
    "        ## add reward from score in game\n",
    "        if(moves_count != 0):\n",
    "            new_score = int(story['Score'][moves_count]) - int(story['Score'][moves_count-1])\n",
    "            reward = reward + new_score*game_score_weight\n",
    "\n",
    "        ## add small negative reward for each move\n",
    "        reward = reward - negative_per_turn_reward\n",
    "\n",
    "        ## add reward for picking up / using items\n",
    "        if(moves_count != 0):\n",
    "            pre_inventory = story['Inventory'][moves_count-1]\n",
    "            inventory = story['Inventory'][moves_count]\n",
    "            if pre_inventory != inventory:  ## inventory changed\n",
    "                reward = reward + inventory_reward_value\n",
    "                print('inventory changed')\n",
    "\n",
    "\n",
    "        ## add reward for discovering new areas\n",
    "        if new_narrative not in unique_narratives:  ## new location\n",
    "            reward = reward + new_area_reward_value\n",
    "            print('discovered new area')\n",
    "        print(reward)\n",
    "        return reward\n",
    "\n",
    "    def detect_invalid_nouns(self, action_response):\n",
    "        ## detect and remove invalid nouns from future turns\n",
    "        action_response = preprocess(str(action_response))\n",
    "        if('don\\'t know the word' in response):\n",
    "            startIndex = action_response.find('\\\"')\n",
    "            endIndex = action_response.find('\\\"', startIndex + 1)\n",
    "            word = action_response[startIndex+1:endIndex]\n",
    "            print('Didn\\'t know the word: ' + word)\n",
    "            invalid_nouns.append(word)\n",
    "    \n",
    "    def save_invalid_nouns(self):\n",
    "        ## save invalid nouns to pickled list\n",
    "        try:\n",
    "            with open('invalid_nouns.txt', 'wb') as fp:\n",
    "                pickle.dump(invalid_nouns, fp)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    def load_invalid_nouns(self):\n",
    "        ## load previously found invalid nouns from pickled list\n",
    "        try:\n",
    "            with open ('invalid_nouns.txt', 'rb') as fp:\n",
    "                n = pickle.load(fp)\n",
    "                invalid_nouns.extend(n)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    def init_word2vec(self):\n",
    "        #model = Word2Vec.load('tutorial.model')\n",
    "        f = open(tutorials_text, 'r')\n",
    "        tutorials = f.read()\n",
    "        sentences = word_tokenize(tutorials)\n",
    "        model = Word2Vec([sentences])\n",
    "        return model\n",
    "    \n",
    "    def init_tokenizer(self):\n",
    "        tokenizer = Tokenizer(num_words=vocab_size)\n",
    "        \n",
    "    def run_game(self, agent, num_rounds):\n",
    "        pbar = ProgressBar(maxval=num_rounds)\n",
    "        pbar.start()\n",
    "        try:\n",
    "            for i in range(0,num_rounds):\n",
    "                ## Check surroundings, check inventory, choose action, check action response\n",
    "                narrative,score,moves = readLine(q)\n",
    "                check_inventory(p)\n",
    "                inventory,s,m = readLine(q)\n",
    "                \n",
    "                ## grab nouns in current env\n",
    "                nouns = get_nouns(narrative)\n",
    "\n",
    "                # build action space\n",
    "                current_action_space = generate_action_tuples(nouns)\n",
    "                action_space = set()\n",
    "                action_space, probs = add_to_action_space(action_space, current_action_space)\n",
    "                actions = []\n",
    "                for a in action_space:\n",
    "                    actions.append(a)\n",
    "\n",
    "                narrativeVector = vectorizeText(narrative,tokenizer)\n",
    "\n",
    "                ## decide which type of action to perform\n",
    "                if (agent.act_random() or i < 10): ## choose random action\n",
    "                    print('random choice')\n",
    "                    probs = np.array(probs)\n",
    "                    probs /= probs.sum()\n",
    "                    action = selectOne(actions, probs)\n",
    "                    df = pd.DataFrame(columns=['Action', 'Prob'])\n",
    "                    df['Action'] = actions\n",
    "                    df['Prob'] = probs\n",
    "\n",
    "                else: ## choose predicted max Q value action\n",
    "                    print('predicted choice')\n",
    "                    actionsVectors = []\n",
    "                    for a in actions:\n",
    "                        actionsVectors.append(vectorizeText(a,tokenizer))\n",
    "                    best_action, max_q = agent.predict_actions(narrativeVector, actionsVectors)\n",
    "                    action = actions[best_action]\n",
    "\n",
    "                ## perform selected action\n",
    "                perform_action(action, p)\n",
    "\n",
    "                ## grab response from action\n",
    "                response,score,moves = readLine(q)\n",
    "                story.loc[i] = [narrative, inventory, action, response, str(s), str(i+1)]\n",
    "                unique_narratives.add(preprocess(narrative))\n",
    "\n",
    "                actionVector = vectorizeText(action,tokenizer)\n",
    "\n",
    "                look_surroundings(p)\n",
    "                new_narrative,s,m = readLine(q)\n",
    "                new_narrativeVector = vectorizeText(new_narrative, tokenizer)\n",
    "\n",
    "                \n",
    "                # get reward\n",
    "                reward = calculate_reward(story, i, preprocess(new_narrative))\n",
    "\n",
    "                agent.remember(narrativeVector, actionVector, reward, new_narrativeVector, False)\n",
    "\n",
    "                look_surroundings(p)\n",
    "\n",
    "                if moves_count%batch_size == 0:  ## batch of 5 experiences in memory\n",
    "                    agent.replay(batch_size)\n",
    "\n",
    "                pbar.update(i) ## update progress bar\n",
    "            pbar.finish()\n",
    "            kill_game(p)\n",
    "        except Exception as e: \n",
    "            kill_game(p)\n",
    "            print(e.with_traceback())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
